# ğŸ‡¬ğŸ‡§â¡ï¸ğŸ‡®ğŸ‡³ English â†’ Hindi Neural Machine Translation (Transformer, PyTorch)

A **single-file, production-ready Encoderâ€“Decoder Transformer** for **English â†’ Hindi** translation, implemented in **pure PyTorch** and trained on the **CFILT IITB Englishâ€“Hindi dataset**.

This project focuses on **robustness, reproducibility, and practical training concerns**, including Windows-safe multiprocessing, lazy SentencePiece loading, AMP training, and optional `torch.compile()` acceleration.

---

## âœ¨ Features

- ğŸ” **Encoderâ€“Decoder Transformer** (from scratch, no `nn.Transformer`)
- ğŸ“š **CFILT IITB Englishâ€“Hindi** dataset support (`datasets` library)
- ğŸ§© **Robust dataset field extraction** (handles nested & irregular schemas)
- ğŸ”¤ **SentencePiece BPE tokenization**
  - Joint Englishâ€“Hindi vocabulary
  - Lazy, worker-safe loading
- âš¡ **Mixed Precision Training (AMP)** with `GradScaler`
- ğŸ§µ **Windows-safe DataLoader**
  - Automatic fallback if multi-worker loading fails
- ğŸš€ **Optional `torch.compile()`** (PyTorch 2.x, safe fallback)
- ğŸ“Š **BLEU evaluation** (via `sacrebleu`)
- â±ï¸ **ETA & performance tracking**
- ğŸ” **Greedy + Beam Search decoding**
- ğŸ“¦ **Single-file implementation** for easy inspection & modification

---

## ğŸ§  Model Architecture

- Token + positional embeddings  
- 6-layer Transformer Encoder  
- 6-layer Transformer Decoder  
- Multi-head self-attention & cross-attention  
- LayerNorm + residual connections  
- Vocabulary size: **32,000 (SentencePiece BPE)**  

---

## ğŸ“¦ Requirements

```bash
pip install torch datasets sentencepiece sacrebleu tqdm
